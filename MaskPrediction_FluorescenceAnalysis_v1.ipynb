{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaskPrediction_FluorescenceAnalysis_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolineWeeLab/EZgut/blob/main/MaskPrediction_FluorescenceAnalysis_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segmentations of the gut are generated by our custom-trained Pointrend model. This notebook does not include the curation of predicted masks, but if critical errors are discovered upon visualisation of the masks, we suggest that they are editted in ImageJ using selection and ROI tools. The corrected masks can then be replaced in the folder to proceed with fluorescence analysis.\n",
        "\n",
        "We make use of free Google Colab's GPU runtime so that the notebook can be run on a basic laptop with internet connection, without the need for a local GPU.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Updated: 16 March 2022"
      ],
      "metadata": {
        "id": "J3H3OlqNtQAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packges\n",
        "\n",
        "We use Detectron2's [Pointrend](https://github.com/facebookresearch/detectron2/tree/main/projects/PointRend) model and train it further on out custom dataset."
      ],
      "metadata": {
        "id": "pVz83ykXFP1R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxvONgAzKC7M"
      },
      "source": [
        "# make sure to connect to GPU run time\n",
        "\n",
        "!pip install pyyaml==5.1\n",
        "# This is the current pytorch version on Colab. Uncomment this if Colab changes its pytorch version\n",
        "!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DALhiKopKMAL"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "Zbh3mxzkFVOx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RxD4P0GKT_x"
      },
      "source": [
        "# mount drive and load data\n",
        "# data should be google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask generation"
      ],
      "metadata": {
        "id": "TJTmHj2eFaDw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48KFj_HqKebA"
      },
      "source": [
        "Please ensure that the model file has been downloaded and that the correct path is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMpJC1iRKh0h"
      },
      "source": [
        "# Obtain predictions and save masks\n",
        "\n",
        "cfg = get_cfg()\n",
        "\n",
        "################################################################################\n",
        "#EDIT THIS PART ONLY\n",
        "\n",
        "cfg.MODEL.WEIGHTS = \"model_final.pth\"  # path to the model \n",
        "\n",
        "################################################################################\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"gut_train\",)\n",
        "cfg.DATASETS.TEST = (\"gut_test\")\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1200    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 # minimum detection score for object to be considered\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5 # NMS for boxes with IOU > thresh\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "gut_metadata = MetadataCatalog.get(\"gut_train_v3\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate and save masks of the brightfield images. \n",
        "directory is where BF images are stored. \n",
        "savedir is where output masks will be saved. ",
        "Both tif and jpg formats are allowed in this model. To use jpg, edit code to filename.endswith(\"jpg\")"
      ],
      "metadata": {
        "id": "_P0ERg8xEfPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "################################################################################\n",
        "#EDIT THIS PART ONLY\n",
        "\n",
        "directory = \"\" # directory containing the brightfield images\n",
        "savedir = \"\" # directory to save predicted masks\n",
        "\n",
        "################################################################################\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\"tif\"): # if performance is poor, consider enhancing brightness + contrast in ImageJ\n",
        "        im = cv2.imread(os.path.join(directory,filename))\n",
        "        outputs = predictor(im)\n",
        "        mask = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy() \n",
        "        msks = []\n",
        "        # each instance is a separate mask so mask size is n_instances*image_height*image_width\n",
        "        for m in mask:\n",
        "            msks.append(m)\n",
        "            ms = np.sum(msks[:], axis=0) # compiles all the instances in one image to 1 binary mask image\n",
        "            ms = np.asarray(ms, np.float)\n",
        "            m,M = ms.min(), ms.max()\n",
        "            I = np.asarray((ms - m) / (M - m + 0.000001) * 65535, np.uint16) \n",
        "            I = np.where(I < 1,0,65535)\n",
        "            I = np.asarray(I, dtype=np.int8)\n",
        "            I= Image.fromarray(I).convert('L') \n",
        "            I.save(os.path.join(savedir,filename + '_mask.png')) "
      ],
      "metadata": {
        "id": "0dau2Oc9At1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisation"
      ],
      "metadata": {
        "id": "Zw2vcTxNIloY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHIgbK_nLTSl"
      },
      "source": [
        "To check prediction masks of one image or for visualisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "im = cv2.imread(\"BF_testimage.tif\")\n",
        "outputs = predictor(im)\n",
        "v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=gut_metadata, \n",
        "                scale=0.8, \n",
        "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        ")\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "HfWuJ3QnBIAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check prediction masks of all images in folder, not recommended if there a lot of images"
      ],
      "metadata": {
        "id": "jFHktmkZD-tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#EDIT THIS PART ONLY\n",
        "\n",
        "directory = \"\"\n",
        "\n",
        "################################################################################\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\"tif\"):\n",
        "        im = cv2.imread(os.path.join(directory,filename))\n",
        "        outputs = predictor(im)\n",
        "        v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=gut_metadata, \n",
        "                scale=0.8, \n",
        "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "        )\n",
        "        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "        cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "nqumXp3yD92F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fluorescence analysis\n",
        "\n",
        "Fill in ch1name as the channel name of your fluorescence channel. We use Cy5.\n",
        "\n",
        "Your file hierachy should look like (results.csv is created by this cell):\n",
        "\n",
        "```\n",
        "maindir\n",
        "│   \n",
        "└───BFmask\n",
        "│   │   BF_sample1_mask.png\n",
        "|   |   BF_sample2_mask.png\n",
        "│   \n",
        "└───BF\n",
        "|   │   BF_sample1.tif\n",
        "|   |   BF_sample2.tif\n",
        "|   \n",
        "└───Cy5\n",
        "|   │   Cy5_sample1.tif\n",
        "|   |   Cy5_sample2.tif\n",
        "|\n",
        "|   results.csv\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ttx97DluZBw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "################################################################################\n",
        "#EDIT THIS PART ONLY\n",
        "\n",
        "ch1name = \"Cy5\"\n",
        "maindir = \"\" # directory where all the BFmask, Cy5 etc. are stored\n",
        "\n",
        "################################################################################\n",
        "\n",
        "BFmaskdir = os.path.join(maindir,\"BFmask\")\n",
        "ch1 = os.path.join(maindir,ch1name)\n",
        "\n",
        "results_dict = {}\n",
        "\n",
        "for im in os.listdir(BFmaskdir):\n",
        "    if im.endswith('png'):\n",
        "\n",
        "        maskim = cv.imread(os.path.join(BFmaskdir,im),0)\n",
        "        if len(maskim.shape) != 2:\n",
        "            raise Exception(\"mask image has more than 1 channel\")\n",
        "\n",
        "        imname = im.split('--')[0]\n",
        "        ch1_im_name = [filename for filename in os.listdir(ch1) if filename.startswith(imname)][0]\n",
        "        intensityim_ch1 = cv.imread(os.path.join(ch1,ch1_im_name),-1)\n",
        "        if intensityim_ch1.dtype != 'uint16':\n",
        "            #raise Exception('Channel 1 image is not 16 bit')\n",
        "            print('Channel 1 image is not 16 bit')\n",
        "\n",
        "        labeledim = cv.connectedComponentsWithStats(maskim)\n",
        "        fishnum = labeledim[0] - 1 # subtract 1 for background\n",
        "\n",
        "        ch1_mean_list = []\n",
        "        for i in range(1,fishnum + 1):\n",
        "            gutmask = labeledim[1] == i\n",
        "            gutintensity_ch1 = gutmask * intensityim_ch1\n",
        "            ch1mean_temp = gutintensity_ch1[gutintensity_ch1!=0].mean()\n",
        "            ch1_mean_list.append(ch1mean_temp)\n",
        "            results_dict[imname] = ch1_mean_list\n",
        "\n",
        "results_df = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in results_dict.items()]))\n",
        "results_df.to_csv(os.path.join(maindir,'results.csv'),index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "VP_qrpZXZWv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
